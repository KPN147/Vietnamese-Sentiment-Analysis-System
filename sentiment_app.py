import gradio as gr
import torch
import numpy as np
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from transformers import pipeline

class SentimentAnalyzer:
    def __init__(self, sentiment_model_name , speech_model_name):
        print(" Äang táº£i models...")

        try:
            self.sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)
            self.sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name)
            self.sentiment_model.eval()

            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.sentiment_model.to(self.device)
            print(f" PhoBERT sentiment model Ä‘Ã£ táº£i thÃ nh cÃ´ng! (Device: {self.device})")
        except Exception as e:
            print(f" Lá»—i khi táº£i PhoBERT model: {e}")
            self.sentiment_model = None
            self.sentiment_tokenizer = None

        try:
            self.speech_pipeline = pipeline(
                "automatic-speech-recognition",
                model=speech_model_name,
                device=0 if torch.cuda.is_available() else -1  # 0 for GPU, -1 for CPU
            )
            print(f" PhoWhisper model Ä‘Ã£ táº£i thÃ nh cÃ´ng!")
        except Exception as e:
            print(f" Lá»—i khi táº£i PhoWhisper model: {e}")
            self.speech_pipeline = None

    def predict_sentiment_from_text(self, text):
        if not text or text.strip() == "":
            return "Vui lÃ²ng nháº­p vÄƒn báº£n!", {}

        if self.sentiment_model is None or self.sentiment_tokenizer is None:
            return " Model chÆ°a Ä‘Æ°á»£c táº£i!", {}

        try:

            inputs = self.sentiment_tokenizer(
                text,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=256
            )

            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            with torch.no_grad():
                outputs = self.sentiment_model(**inputs)

            probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)[0]
            prediction = torch.argmax(outputs.logits, dim=1).item()

            probabilities = probabilities.cpu().numpy()

            sentiment = "TÃ­ch cá»±c âœ…" if prediction == 1 else "TiÃªu cá»±c âŒ"
            confidence = float(probabilities[prediction]) * 100

            result_text = f"**Káº¿t quáº£:** {sentiment}\n**Äá»™ tin cáº­y:** {confidence:.2f}%"
            prob_dict = {
                "TiÃªu cá»±c ğŸ˜": float(probabilities[0]),
                "TÃ­ch cá»±c ğŸ˜Š": float(probabilities[1])
            }

            return result_text, prob_dict

        except Exception as e:
            return f" Lá»—i khi dá»± Ä‘oÃ¡n: {str(e)}", {}

    def speech_to_text(self, audio_path):
        if audio_path is None:
            return "Vui lÃ²ng táº£i lÃªn file audio!"

        if self.speech_pipeline is None:
            return " PhoWhisper model chÆ°a Ä‘Æ°á»£c táº£i!"

        try:
            result = self.speech_pipeline(audio_path)
            text = result["text"]

            if not text or text.strip() == "":
                return "âš ï¸ KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c vÄƒn báº£n tá»« audio. Vui lÃ²ng thá»­ file khÃ¡c."

            return text

        except Exception as e:
            return f"âŒ Lá»—i khi chuyá»ƒn Ä‘á»•i audio: {str(e)}"

    def predict_sentiment_from_audio(self, audio_path):

        if audio_path is None:
            return "Vui lÃ²ng táº£i lÃªn file audio!", "", {}


        text = self.speech_to_text(audio_path)


        sentiment, prob_dict = self.predict_sentiment_from_text(text)

        return text, sentiment, prob_dict


SENTIMENT_MODEL_NAME =  "KPN14/phobert_sentiment"
SPEECH_MODEL_NAME = "vinai/PhoWhisper-large"


print(" Äang khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng...")
analyzer = SentimentAnalyzer(
    sentiment_model_name=SENTIMENT_MODEL_NAME,
    speech_model_name=SPEECH_MODEL_NAME
)


with gr.Blocks(title="PhÃ¢n tÃ­ch cáº£m xÃºc", theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        # ğŸ­ Há»‡ thá»‘ng PhÃ¢n tÃ­ch Cáº£m xÃºc
        á»¨ng dá»¥ng phÃ¢n tÃ­ch cáº£m xÃºc tá»« vÄƒn báº£n vÃ  Ã¢m thanh
        """
    )

    with gr.Tabs():

        with gr.Tab("ğŸ“ PhÃ¢n tÃ­ch tá»« vÄƒn báº£n"):
            gr.Markdown("### Nháº­p vÄƒn báº£n Ä‘á»ƒ phÃ¢n tÃ­ch cáº£m xÃºc")
            with gr.Row():
                with gr.Column():
                    text_input = gr.Textbox(
                        label="Nháº­p vÄƒn báº£n",
                        placeholder="Nháº­p vÄƒn báº£n tiáº¿ng Viá»‡t cá»§a báº¡n...",
                        lines=5
                    )
                    text_submit_btn = gr.Button("PhÃ¢n tÃ­ch", variant="primary")

                with gr.Column():
                    text_output = gr.Textbox(
                        label="Káº¿t quáº£ dá»± Ä‘oÃ¡n",
                        interactive=False,
                        lines=3
                    )
                    text_prob_output = gr.Label(
                        label="PhÃ¢n bá»‘ xÃ¡c suáº¥t",
                        num_top_classes=2
                    )

            gr.Examples(
                examples=[
                    ["Sáº£n pháº©m nÃ y tháº­t tuyá»‡t vá»i!"],
                    ["TÃ´i ráº¥t tháº¥t vá»ng vá» dá»‹ch vá»¥."],
                    ["Äá»“ Äƒn ngon, khÃ´ng gian Ä‘áº¹p, nhÃ¢n viÃªn thÃ¢n thiá»‡n."],
                    ["Cháº¥t lÆ°á»£ng kÃ©m, khÃ´ng Ä‘Ã¡ng tiá»n."]
                ],
                inputs=text_input
            )


        with gr.Tab("ğŸ¤ Chuyá»ƒn giá»ng nÃ³i thÃ nh vÄƒn báº£n"):
            gr.Markdown("### Táº£i lÃªn file audio Ä‘á»ƒ chuyá»ƒn thÃ nh vÄƒn báº£n")
            with gr.Row():
                with gr.Column():
                    audio_input_stt = gr.Audio(
                        label="Táº£i lÃªn file audio",
                        type="filepath"
                    )
                    stt_submit_btn = gr.Button("Chuyá»ƒn Ä‘á»•i", variant="primary")

                with gr.Column():
                    stt_output = gr.Textbox(
                        label="VÄƒn báº£n nháº­n dáº¡ng",
                        interactive=False,
                        lines=5
                    )


        with gr.Tab("ğŸµ PhÃ¢n tÃ­ch cáº£m xÃºc tá»« Ã¢m thanh"):
            gr.Markdown("### Táº£i lÃªn file audio Ä‘á»ƒ phÃ¢n tÃ­ch cáº£m xÃºc")
            with gr.Row():
                with gr.Column():
                    audio_input_sentiment = gr.Audio(
                        label="Táº£i lÃªn file audio",
                        type="filepath"
                    )
                    audio_submit_btn = gr.Button("PhÃ¢n tÃ­ch", variant="primary")

                with gr.Column():
                    audio_text_output = gr.Textbox(
                        label="VÄƒn báº£n nháº­n dáº¡ng",
                        interactive=False,
                        lines=3
                    )
                    audio_sentiment_output = gr.Textbox(
                        label="Káº¿t quáº£ phÃ¢n tÃ­ch cáº£m xÃºc",
                        interactive=False,
                        lines=3
                    )
                    audio_prob_output = gr.Label(
                        label="PhÃ¢n bá»‘ xÃ¡c suáº¥t",
                        num_top_classes=2
                    )


    text_submit_btn.click(
        fn=analyzer.predict_sentiment_from_text,
        inputs=text_input,
        outputs=[text_output, text_prob_output]
    )

    stt_submit_btn.click(
        fn=analyzer.speech_to_text,
        inputs=audio_input_stt,
        outputs=stt_output
    )

    audio_submit_btn.click(
        fn=analyzer.predict_sentiment_from_audio,
        inputs=audio_input_sentiment,
        outputs=[audio_text_output, audio_sentiment_output, audio_prob_output]
    )

    gr.Markdown(
        """
        ---
        ğŸ’¡ **HÆ°á»›ng dáº«n sá»­ dá»¥ng:**
        - **Tab 1**: Nháº­p vÄƒn báº£n trá»±c tiáº¿p Ä‘á»ƒ phÃ¢n tÃ­ch cáº£m xÃºc
        - **Tab 2**: Táº£i file audio lÃªn Ä‘á»ƒ chuyá»ƒn thÃ nh vÄƒn báº£n
        - **Tab 3**: Táº£i file audio lÃªn Ä‘á»ƒ vá»«a chuyá»ƒn thÃ nh vÄƒn báº£n vá»«a phÃ¢n tÃ­ch cáº£m xÃºc
        """
    )


if __name__ == "__main__":
    demo.launch(
        share= False,
        server_name="0.0.0.0",
        server_port=7860
    )
